{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "K8rPS5-aTUys"
   },
   "source": [
    "# FineTuning BERT for Multi-Class Classification with custom datasets\n",
    "\n",
    "### [Link to Dataset](https://www.kaggle.com/datasets/savasy/ttc4900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n"
     ]
    },
    {
     "ename": "DeferredCudaCallError",
     "evalue": "CUDA call failed lazily at initialization with error: module 'torch' has no attribute 'version'\n\nCUDA call was originally invoked at:\n\n  File \"d:\\Arun Nitc\\New folder\\envs\\py310\\lib\\runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"d:\\Arun Nitc\\New folder\\envs\\py310\\lib\\runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"d:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n    app.launch_new_instance()\n  File \"d:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n    app.start()\n  File \"d:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n    self.io_loop.start()\n  File \"d:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n    self.asyncio_loop.run_forever()\n  File \"d:\\Arun Nitc\\New folder\\envs\\py310\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n    self._run_once()\n  File \"d:\\Arun Nitc\\New folder\\envs\\py310\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n    handle._run()\n  File \"d:\\Arun Nitc\\New folder\\envs\\py310\\lib\\asyncio\\events.py\", line 80, in _run\n    self._context.run(self._callback, *self._args)\n  File \"d:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n    await self.process_one()\n  File \"d:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n    await dispatch(*args)\n  File \"d:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n    await result\n  File \"d:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n    await super().execute_request(stream, ident, parent)\n  File \"d:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n    reply_content = await reply_content\n  File \"d:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n    res = shell.run_cell(\n  File \"d:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"d:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3077, in run_cell\n    result = self._run_cell(\n  File \"d:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3132, in _run_cell\n    result = runner(coro)\n  File \"d:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n    coro.send(None)\n  File \"d:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3336, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"d:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3519, in run_ast_nodes\n    if await self.run_code(code, result, async_=asy):\n  File \"d:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3579, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"C:\\Users\\aruna\\AppData\\Local\\Temp\\ipykernel_26680\\4265195184.py\", line 1, in <module>\n    import torch\n  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n  File \"d:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\torch\\__init__.py\", line 2046, in <module>\n    _C._initExtension(_manager_path())\n  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n  File \"d:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\torch\\cuda\\__init__.py\", line 264, in <module>\n    _lazy_call(_check_capability)\n  File \"d:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\torch\\cuda\\__init__.py\", line 261, in _lazy_call\n    _queued_calls.append((callable, traceback.format_stack()))\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32md:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\torch\\cuda\\__init__.py:330\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 330\u001b[0m     \u001b[43mqueued_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32md:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\torch\\cuda\\__init__.py:197\u001b[0m, in \u001b[0;36m_check_capability\u001b[1;34m()\u001b[0m\n\u001b[0;32m    191\u001b[0m old_gpu_warn \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;124mFound GPU\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m which is of cuda capability \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m.\u001b[39m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;124mPyTorch no longer supports this GPU because it is too old.\u001b[39m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;124mThe minimum cuda capability supported by this library is \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m.\u001b[39m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m--> 197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mversion\u001b[49m\u001b[38;5;241m.\u001b[39mcuda \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# on ROCm we don't want this check\u001b[39;00m\n\u001b[0;32m    198\u001b[0m     CUDA_VERSION \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_cuda_getCompiledVersion()  \u001b[38;5;66;03m# noqa: F841\u001b[39;00m\n",
      "File \u001b[1;32md:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\torch\\__init__.py:2681\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m   2679\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m-> 2681\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch' has no attribute 'version'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mDeferredCudaCallError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA available: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrent GPU device: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_device_name\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of GPUs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Get the current device (CPU or GPU)\u001b[39;00m\n",
      "File \u001b[1;32md:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\torch\\cuda\\__init__.py:491\u001b[0m, in \u001b[0;36mget_device_name\u001b[1;34m(device)\u001b[0m\n\u001b[0;32m    479\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_device_name\u001b[39m(device: Optional[_device_t] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    480\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Get the name of a device.\u001b[39;00m\n\u001b[0;32m    481\u001b[0m \n\u001b[0;32m    482\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    489\u001b[0m \u001b[38;5;124;03m        str: the name of the device\u001b[39;00m\n\u001b[0;32m    490\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 491\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_device_properties\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mname\n",
      "File \u001b[1;32md:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\torch\\cuda\\__init__.py:523\u001b[0m, in \u001b[0;36mget_device_properties\u001b[1;34m(device)\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_device_properties\u001b[39m(device: Optional[_device_t] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _CudaDeviceProperties:\n\u001b[0;32m    512\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Get the properties of a device.\u001b[39;00m\n\u001b[0;32m    513\u001b[0m \n\u001b[0;32m    514\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    521\u001b[0m \u001b[38;5;124;03m        _CudaDeviceProperties: the properties of the device\u001b[39;00m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 523\u001b[0m     \u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# will define _get_device_properties\u001b[39;00m\n\u001b[0;32m    524\u001b[0m     device \u001b[38;5;241m=\u001b[39m _get_device_index(device, optional\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    525\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m device \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m device_count():\n",
      "File \u001b[1;32md:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\torch\\cuda\\__init__.py:336\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    332\u001b[0m             msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    333\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA call failed lazily at initialization with error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    334\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA call was originally invoked at:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(orig_traceback)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    335\u001b[0m             )\n\u001b[1;32m--> 336\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m DeferredCudaCallError(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;28mdelattr\u001b[39m(_tls, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_initializing\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mDeferredCudaCallError\u001b[0m: CUDA call failed lazily at initialization with error: module 'torch' has no attribute 'version'\n\nCUDA call was originally invoked at:\n\n  File \"d:\\Arun Nitc\\New folder\\envs\\py310\\lib\\runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"d:\\Arun Nitc\\New folder\\envs\\py310\\lib\\runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"d:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n    app.launch_new_instance()\n  File \"d:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n    app.start()\n  File \"d:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n    self.io_loop.start()\n  File \"d:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n    self.asyncio_loop.run_forever()\n  File \"d:\\Arun Nitc\\New folder\\envs\\py310\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n    self._run_once()\n  File \"d:\\Arun Nitc\\New folder\\envs\\py310\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n    handle._run()\n  File \"d:\\Arun Nitc\\New folder\\envs\\py310\\lib\\asyncio\\events.py\", line 80, in _run\n    self._context.run(self._callback, *self._args)\n  File \"d:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n    await self.process_one()\n  File \"d:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n    await dispatch(*args)\n  File \"d:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n    await result\n  File \"d:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n    await super().execute_request(stream, ident, parent)\n  File \"d:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n    reply_content = await reply_content\n  File \"d:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n    res = shell.run_cell(\n  File \"d:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"d:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3077, in run_cell\n    result = self._run_cell(\n  File \"d:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3132, in _run_cell\n    result = runner(coro)\n  File \"d:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n    coro.send(None)\n  File \"d:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3336, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"d:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3519, in run_ast_nodes\n    if await self.run_code(code, result, async_=asy):\n  File \"d:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3579, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"C:\\Users\\aruna\\AppData\\Local\\Temp\\ipykernel_26680\\4265195184.py\", line 1, in <module>\n    import torch\n  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n  File \"d:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\torch\\__init__.py\", line 2046, in <module>\n    _C._initExtension(_manager_path())\n  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n  File \"d:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\torch\\cuda\\__init__.py\", line 264, in <module>\n    _lazy_call(_check_capability)\n  File \"d:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\torch\\cuda\\__init__.py\", line 261, in _lazy_call\n    _queued_calls.append((callable, traceback.format_stack()))\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA (GPU) is available\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Current GPU device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "    \n",
    "# Get the current device (CPU or GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25729,
     "status": "ok",
     "timestamp": 1625398158764,
     "user": {
      "displayName": "Savas Yıldırım",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64",
      "userId": "10717726124681851716"
     },
     "user_tz": -180
    },
    "id": "bixw-FrJ-6La",
    "outputId": "850fe9c3-dc21-4036-bcde-b1b0b5c43034"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.models.bert.modeling_bert because of the following error (look up to see its traceback):\nmodule 'torch' has no attribute 'version'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32md:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\transformers\\utils\\import_utils.py:1967\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1966\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1967\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1968\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32md:\\Arun Nitc\\New folder\\envs\\py310\\lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:883\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32md:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:47\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_outputs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     37\u001b[0m     BaseModelOutputWithPastAndCrossAttentions,\n\u001b[0;32m     38\u001b[0m     BaseModelOutputWithPoolingAndCrossAttentions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     45\u001b[0m     TokenClassifierOutput,\n\u001b[0;32m     46\u001b[0m )\n\u001b[1;32m---> 47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PreTrainedModel\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m apply_chunking_to_forward, find_pruneable_heads_and_indices, prune_linear_layer\n",
      "File \u001b[1;32md:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\transformers\\modeling_utils.py:62\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mflash_attention\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m flash_attention_forward\n\u001b[1;32m---> 62\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mflex_attention\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m flex_attention_forward\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msdpa_attention\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m sdpa_attention_forward\n",
      "File \u001b[1;32md:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\transformers\\integrations\\flex_attention.py:37\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torch_flex_attn_available():\n\u001b[1;32m---> 37\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mattention\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mflex_attention\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BlockMask, flex_attention\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mattention\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mflex_attention\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     39\u001b[0m         create_block_mask \u001b[38;5;28;01mas\u001b[39;00m create_block_causal_mask_flex,\n\u001b[0;32m     40\u001b[0m     )\n",
      "File \u001b[1;32md:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\torch\\nn\\attention\\flex_attention.py:16\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Tensor\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_trace_wrapped_higher_order_op\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TransformGetItemToIndex\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_higher_order_ops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mflex_attention\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m flex_attention \u001b[38;5;28;01mas\u001b[39;00m flex_attention_hop\n",
      "File \u001b[1;32md:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\torch\\_dynamo\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m convert_frame, eval_frame, resume_execution\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m list_backends, lookup_backend, register_backend\n",
      "File \u001b[1;32md:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py:33\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_compile_pg\n\u001b[1;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msymbolic_convert\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TensorifyState\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_guards\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compile_context, CompileContext, CompileId, tracing\n",
      "File \u001b[1;32md:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py:27\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_logging\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TensorifyScalarRestartAnalysis\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_guards\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tracing, TracingContext\n",
      "File \u001b[1;32md:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\torch\\_dynamo\\exc.py:11\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m counters\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n",
      "File \u001b[1;32md:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\torch\\_dynamo\\utils.py:65\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_functorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msymbolic_shapes\u001b[39;00m\n",
      "File \u001b[1;32md:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\torch\\_functorch\\config.py:66\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# When AOTAutograd regenerates aliased graph outputs,\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# attempt to use functionalization's view-replay logic\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# before falling back to the autograd engine's view replay or as_strided.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# once XLA pin update works,\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# or default config to true and fix relevant bugs\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_inductor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_fbcode\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# View replay is currently not compatible with AOTAutogradCache, since\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# FunctionalTensors are not serializable. We'll need to make them\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# serializable before enabling warm cache with this config turned on.\u001b[39;00m\n",
      "File \u001b[1;32md:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\torch\\_inductor\\__init__.py:9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Dict, List, Optional, Tuple, TYPE_CHECKING, Union\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_inductor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\n",
      "File \u001b[1;32md:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\torch\\_inductor\\config.py:404\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;66;03m# Disabled by default on ROCm, opt-in if model utilises NHWC convolutions\u001b[39;00m\n\u001b[1;32m--> 404\u001b[0m layout_opt_default \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mversion\u001b[49m\u001b[38;5;241m.\u001b[39mhip \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    405\u001b[0m layout_optimization \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    406\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTORCHINDUCTOR_LAYOUT_OPTIMIZATION\u001b[39m\u001b[38;5;124m\"\u001b[39m, layout_opt_default) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    407\u001b[0m )\n",
      "File \u001b[1;32md:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\torch\\__init__.py:2681\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m   2679\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m-> 2681\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch' has no attribute 'version'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BertForSequenceClassification, BertTokenizerFast\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1075\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[1;32md:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\transformers\\utils\\import_utils.py:1956\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1954\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m   1955\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module[name])\n\u001b[1;32m-> 1956\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1957\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules:\n\u001b[0;32m   1958\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(name)\n",
      "File \u001b[1;32md:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\transformers\\utils\\import_utils.py:1955\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1953\u001b[0m     value \u001b[38;5;241m=\u001b[39m Placeholder\n\u001b[0;32m   1954\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m-> 1955\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1956\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[0;32m   1957\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules:\n",
      "File \u001b[1;32md:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\transformers\\utils\\import_utils.py:1969\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1967\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m   1968\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1969\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1970\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1971\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1972\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to import transformers.models.bert.modeling_bert because of the following error (look up to see its traceback):\nmodule 'torch' has no attribute 'version'"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizerFast\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 397,
     "status": "ok",
     "timestamp": 1625398175947,
     "user": {
      "displayName": "Savas Yıldırım",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64",
      "userId": "10717726124681851716"
     },
     "user_tz": -180
    },
    "id": "XGvn9cWEtXcE",
    "outputId": "8ddd76d1-8416-481f-bad5-52a6d4bb0672"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4343</th>\n",
       "      <td>4426</td>\n",
       "      <td>A mio avviso troppo dispersivo ...quasi ci si ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8256</th>\n",
       "      <td>8405</td>\n",
       "      <td>Bello anche d'inverno! Noi l'abbiamo percorso ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6526</th>\n",
       "      <td>6652</td>\n",
       "      <td>Tyggegummi-pop for voksne på Britney Spears’ &lt;...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25186</th>\n",
       "      <td>25689</td>\n",
       "      <td>Chegou bem emabalado, Muito antes do Prazo. Fu...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24283</th>\n",
       "      <td>24761</td>\n",
       "      <td>Hotel antiguo, sin servicio de habitaciones ni...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                            Comment Sentiment\n",
       "4343         4426  A mio avviso troppo dispersivo ...quasi ci si ...  Positive\n",
       "8256         8405  Bello anche d'inverno! Noi l'abbiamo percorso ...  Positive\n",
       "6526         6652  Tyggegummi-pop for voksne på Britney Spears’ <...   Neutral\n",
       "25186       25689  Chegou bem emabalado, Muito antes do Prazo. Fu...  Positive\n",
       "24283       24761  Hotel antiguo, sin servicio de habitaciones ni...  Negative"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "ROOT_DIR = 'D:\\Downloads\\TrainingSet (1).csv'\n",
    "\n",
    "df_org= pd.read_csv(ROOT_DIR)\n",
    "\n",
    "df_org = df_org.sample(frac=1.0, random_state=42)\n",
    "\n",
    "df_org.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Positive', 'Neutral', 'Negative']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = df_org['Sentiment'].unique().tolist()\n",
    "labels = [s.strip() for s in labels ]\n",
    "labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Why we need id2label and labe2ids in NLP Projects\n",
    "\n",
    "In NLP tasks, especially those involving classification problems, id2label and label2id dictionaries are used to map class labels (categories) to integer IDs and vice versa. These mappings are essential for various stages of the NLP pipeline, such as data preprocessing, model training, and evaluation.\n",
    "\n",
    "Data preprocessing: In order to feed text data into an NLP model, the text must first be tokenized and then converted into numerical values. Similarly, class labels must also be transformed into numerical representations. The label2id dictionary helps in converting the original class labels into integer IDs.\n",
    "\n",
    "Model training: NLP models usually output probability distributions over classes as their predictions. During training, the model's predictions are compared against the ground truth labels (which have been converted to integer IDs) to compute the loss and optimize the model parameters.\n",
    "\n",
    "Model evaluation and interpretation: Once the model has been trained, its predictions (in the form of integer IDs) need to be mapped back to their original class labels to make the results interpretable. The id2label dictionary is used to perform this conversion.\n",
    "\n",
    "\n",
    "For `BertForSequenceClassification` model as well I need these exact mapping of id2labels and labels2id in dictionary form.\n",
    "\n",
    "### Hence, fefore you start training your model, create a map of the expected ids to their labels with id2label and label2id:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n",
      "Neutral\n",
      "Negative\n"
     ]
    }
   ],
   "source": [
    "for key, value in enumerate(labels):\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1625398177852,
     "user": {
      "displayName": "Savas Yıldırım",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64",
      "userId": "10717726124681851716"
     },
     "user_tz": -180
    },
    "id": "5jyOH3YGvyYW"
   },
   "outputs": [],
   "source": [
    "NUM_LABELS= len(labels)\n",
    "\n",
    "id2label={id:label for id,label in enumerate(labels)}\n",
    "\n",
    "label2id={label:id for id,label in enumerate(labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1625398179284,
     "user": {
      "displayName": "Savas Yıldırım",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64",
      "userId": "10717726124681851716"
     },
     "user_tz": -180
    },
    "id": "MQ6iJXbFn86y",
    "outputId": "51bcfc45-6c5e-4f88-a971-ac34e7b6d2bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Positive': 0, 'Neutral': 1, 'Negative': 2}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 395,
     "status": "ok",
     "timestamp": 1625398182914,
     "user": {
      "displayName": "Savas Yıldırım",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64",
      "userId": "10717726124681851716"
     },
     "user_tz": -180
    },
    "id": "EJYWAXVovqOQ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Positive', 1: 'Neutral', 2: 'Negative'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4343</th>\n",
       "      <td>4426</td>\n",
       "      <td>A mio avviso troppo dispersivo ...quasi ci si ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8256</th>\n",
       "      <td>8405</td>\n",
       "      <td>Bello anche d'inverno! Noi l'abbiamo percorso ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6526</th>\n",
       "      <td>6652</td>\n",
       "      <td>Tyggegummi-pop for voksne på Britney Spears’ &lt;...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25186</th>\n",
       "      <td>25689</td>\n",
       "      <td>Chegou bem emabalado, Muito antes do Prazo. Fu...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24283</th>\n",
       "      <td>24761</td>\n",
       "      <td>Hotel antiguo, sin servicio de habitaciones ni...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                            Comment Sentiment\n",
       "4343         4426  A mio avviso troppo dispersivo ...quasi ci si ...  Positive\n",
       "8256         8405  Bello anche d'inverno! Noi l'abbiamo percorso ...  Positive\n",
       "6526         6652  Tyggegummi-pop for voksne på Britney Spears’ <...   Neutral\n",
       "25186       25689  Chegou bem emabalado, Muito antes do Prazo. Fu...  Positive\n",
       "24283       24761  Hotel antiguo, sin servicio de habitaciones ni...  Negative"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_org.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new column to represent the categories in numerical form\n",
    "\n",
    "I need a 'label' column heading with numeric value else while running the epochs with `trainer.train()` I will get below error\n",
    "\n",
    "```\n",
    "BertForSequenceClassification ValueError: The model did not return \n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "### In below I am doing it manually, but I could have also done it with pd.factorize() as below\n",
    "\n",
    "Pandas factorize method is used for encoding categorical variables as integers. It assigns a unique integer value to each distinct category in a given Series or DataFrame, effectively transforming non-numeric data into numeric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_org['labels_num'] = pd.factorize(df_org.category)[0]\n",
    "# df_org.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1625398182915,
     "user": {
      "displayName": "Savas Yıldırım",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64",
      "userId": "10717726124681851716"
     },
     "user_tz": -180
    },
    "id": "HbdFN3VZoawV"
   },
   "outputs": [],
   "source": [
    "df_org[\"labels\"]=df_org.Sentiment.map(lambda x: label2id[x.strip()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1625398183337,
     "user": {
      "displayName": "Savas Yıldırım",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64",
      "userId": "10717726124681851716"
     },
     "user_tz": -180
    },
    "id": "KGAcx7nqwJgm",
    "outputId": "5836de30-de03-480c-8db3-2ab403ac142f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4343</th>\n",
       "      <td>4426</td>\n",
       "      <td>A mio avviso troppo dispersivo ...quasi ci si ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8256</th>\n",
       "      <td>8405</td>\n",
       "      <td>Bello anche d'inverno! Noi l'abbiamo percorso ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6526</th>\n",
       "      <td>6652</td>\n",
       "      <td>Tyggegummi-pop for voksne på Britney Spears’ &lt;...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25186</th>\n",
       "      <td>25689</td>\n",
       "      <td>Chegou bem emabalado, Muito antes do Prazo. Fu...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24283</th>\n",
       "      <td>24761</td>\n",
       "      <td>Hotel antiguo, sin servicio de habitaciones ni...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                            Comment  \\\n",
       "4343         4426  A mio avviso troppo dispersivo ...quasi ci si ...   \n",
       "8256         8405  Bello anche d'inverno! Noi l'abbiamo percorso ...   \n",
       "6526         6652  Tyggegummi-pop for voksne på Britney Spears’ <...   \n",
       "25186       25689  Chegou bem emabalado, Muito antes do Prazo. Fu...   \n",
       "24283       24761  Hotel antiguo, sin servicio de habitaciones ni...   \n",
       "\n",
       "      Sentiment  labels  \n",
       "4343   Positive       0  \n",
       "8256   Positive       0  \n",
       "6526    Neutral       1  \n",
       "25186  Positive       0  \n",
       "24283  Negative       2  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_org.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "executionInfo": {
     "elapsed": 712,
     "status": "ok",
     "timestamp": 1625398187147,
     "user": {
      "displayName": "Savas Yıldırım",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64",
      "userId": "10717726124681851716"
     },
     "user_tz": -180
    },
    "id": "zeNYOXNBGe1B",
    "outputId": "68de8dcd-b392-4915-e5c4-5d21f5004958"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='count'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_org.Sentiment.value_counts().plot(kind='pie', figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115,
     "referenced_widgets": [
      "21fbbe9bd6d94f308668ac1e4c2a51d0",
      "f391632fced34067a6bc7f76034d8d38",
      "d9bad87a40624bbe9a7b8e5021b6b878",
      "6f869fe141f847a881532c74c5d8b269",
      "35a5b5e6ff374b6a80e8677d695a5409",
      "bed0bf19829f4957985091c7f308190c",
      "43a1a07853414f1fbd41c1d7a7e2a7fd",
      "66f31b78d9974a51bd28e01d073b72a7",
      "8ed902a5a04e4bdaac8f961afe52b622",
      "95a51d9d15734391a3895ac76b7a3676",
      "395f10a793684087b6e3747154e17f8d",
      "c905e0961cf84af2bec6a29ddc0d4237",
      "b3652deb88d94a3e91bc0fa58b9dce54",
      "94930151f87e495b974a7f40de2b1db4",
      "4e66a8a8057e4232a3881aef3ac3afa9",
      "a098193923044bfc89afdfa4faf8cc25"
     ]
    },
    "executionInfo": {
     "elapsed": 2705,
     "status": "ok",
     "timestamp": 1625398193149,
     "user": {
      "displayName": "Savas Yıldırım",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64",
      "userId": "10717726124681851716"
     },
     "user_tz": -180
    },
    "id": "r80yPEvU79rx",
    "outputId": "542fee56-a4bc-44c4-814e-8dd3c29eeb7f"
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\", max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "eda88132d04243bcb499af9e82a789ba",
      "b9f606782e924fdd9a22ee6039ef76f2",
      "ce256db990954d9f9782eae9a248b40b",
      "4557e0d687a44a8ab109109094f3ebd6",
      "5db915425bac4d9caba753797e9faf29",
      "6613484a4d0c477fb4ec5a3d4da81a73",
      "d391715c96a84d078976a10fab20265a",
      "0479af3dea114a4b86c98cd104325344",
      "f8532b3abd7e4243a8fb0ade8e0540e7",
      "1886bd7f86534fcea494bef48439e7db",
      "85c4358f5a6e411fbff53e3dfe3eb88d",
      "cfe8a0c3575a49b6b298262ed7acf76d",
      "4622af58d24f4eea8f67f49364118ccd",
      "b42f5e933f494ea69f3dbaac391b5e23",
      "f92aca32755f45c3ba2b8cab79d44eed",
      "dd7628d863794892b9b1fdd7c5e5df42"
     ]
    },
    "executionInfo": {
     "elapsed": 17953,
     "status": "ok",
     "timestamp": 1625398216241,
     "user": {
      "displayName": "Savas Yıldırım",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64",
      "userId": "10717726124681851716"
     },
     "user_tz": -180
    },
    "id": "L7mT5FEU2Jyr",
    "outputId": "b9133277-8b83-47f4-83ee-bdaa1ac55a3f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlptown/bert-base-multilingual-uncased-sentiment and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([3]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([3, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(105879, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'nlptown/bert-base-multilingual-uncased-sentiment',  # replace with your actual model name\n",
    "    num_labels=3,       # specify your desired number of classes\n",
    "    ignore_mismatched_sizes=True  # add this parameter\n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful information and understanding you know about the model from the above output\n",
    "\n",
    "**Model components:** The model consists of several key components, such as:\n",
    "\n",
    "* Embeddings (word, position, and token type embeddings)\n",
    "\n",
    "* Encoder layers (12 layers in this case, each with self-attention, intermediate, and output components)\n",
    "\n",
    "* Layer normalization and dropout layers for regularization\n",
    "\n",
    "* GELU activation functions used in the intermediate layers\n",
    "\n",
    "**Model dimensions:**\n",
    "\n",
    "* Word embeddings: The model has an embedding size of 768 dimensions and a vocabulary size of 32,000 tokens.\n",
    "\n",
    "* Position embeddings: The model can handle input sequences of up to 512 tokens in length.\n",
    "\n",
    "* Encoder layers: The model has 12 encoder layers, each with a hidden size of 768 and an intermediate layer size of 3072.\n",
    "\n",
    "* Task-specific classification layer: The BertForSequenceClassification model is designed for sequence classification tasks. It takes the final hidden state of the [CLS] token and passes it through a linear layer and a softmax function to produce class probabilities. In this case, the model is configured with a custom number of labels (NUM_LABELS) and label mappings (id2label, label2id)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "\n",
    "## Lets understand the flow of a raw input-text > through the pretrained BERT Model > and finally coming out on the other side of the model as a class prediction in the context of this task-specific fine-tuning.\n",
    "\n",
    "In BERT-based models like BertForSequenceClassification, the [CLS] token (short for \"classification\") serves as a special token that is prepended to the input sequence. It is designed to be used as an aggregate representation of the entire input sequence for classification tasks.\n",
    "\n",
    "Here's a step-by-step breakdown of how the [CLS] token is handled during fine-tuning for a specific classification task:\n",
    "\n",
    "Tokenization: During the pre-processing of the input text, the tokenizer inserts the [CLS] token at the beginning of the input sequence. For example, if the input text is \"This is a sample sentence.\", the tokenized input would look like: \"[CLS] This is a sample sentence.\"\n",
    "\n",
    "**Embeddings:** The tokenized input sequence, including the [CLS] token, is passed through the BERT model's embedding layers, which convert the tokens into continuous-valued word vectors.\n",
    "\n",
    "**Encoder layers:** The embedded input sequence is then processed through the BERT model's encoder layers, which consist of self-attention mechanisms and feed-forward neural networks. During this process, the model learns to capture the semantic and syntactic information present in the input sequence, as well as any relationships between the tokens.\n",
    "\n",
    "**Final hidden state of [CLS]:** At the end of the BERT model's encoder layers, each token has a corresponding hidden state vector. For the [CLS] token, its final hidden state is used as an aggregated representation of the entire input sequence. This vector is then passed to the task-specific classification layer.\n",
    "\n",
    "**Linear layer:** The final hidden state of the [CLS] token is fed into a linear layer, which maps the 768-dimensional vector (assuming the base BERT model) to a vector of size equal to the number of target classes. This is essentially a weight matrix multiplication followed by a bias term addition.\n",
    "\n",
    "**Softmax function:** The output of the linear layer is then passed through a softmax function, which converts the raw output values into class probabilities. The softmax function ensures that the sum of probabilities across all classes equals 1.\n",
    "\n",
    "**Prediction:** The class with the highest probability is chosen as the final prediction for the given input sequence.\n",
    "\n",
    "During task-specific fine-tuning, the model learns to adjust its weights and biases based on the training data and the target labels. This involves updating both the BERT model's pre-trained parameters and the task-specific classification layer's parameters through backpropagation and optimization techniques like gradient descent. This fine-tuning process allows the model to adapt to the specific classification task and improve its performance on the given dataset.\n",
    "\n",
    "-------------------\n",
    "\n",
    "## In the above task specific fine tuning do all of the weights of the pretrained BERT model gets modified during this finetuning process or only some of the weights get modified ?\n",
    "\n",
    "\n",
    "During task-specific fine-tuning, all of the weights of the pre-trained BERT model are potentially subject to modification, including the weights in the embedding layers, the encoder layers, and the classification layer. However, the extent to which each weight is modified depends on the learning rate, the specific task, and the training data.\n",
    "\n",
    "In general, fine-tuning a pre-trained model like BERT involves updating its weights to better adapt to the target task. When fine-tuning begins, the initial weights of the model come from the pre-trained model, which has already learned general language representations from a large-scale unsupervised task (e.g., masked language modeling).\n",
    "\n",
    "During fine-tuning, the model is exposed to the particular task-specific training data and labels, and the weights are updated using backpropagation and gradient descent.\n",
    "\n",
    "Typically, the learning rate for fine-tuning is set to be smaller than the learning rate used during pre-training. This is because the pre-trained model already has a good understanding of language, and the fine-tuning process aims to make small, incremental adjustments to the weights to adapt the model to the specific task without losing the valuable general language knowledge."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ZROZOxM9xi3l"
   },
   "source": [
    "## Splitting df_org\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1625398219485,
     "user": {
      "displayName": "Savas Yıldırım",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64",
      "userId": "10717726124681851716"
     },
     "user_tz": -180
    },
    "id": "HM58CfgUZ0oK"
   },
   "outputs": [],
   "source": [
    "SIZE= df_org.shape[0]\n",
    "\n",
    "train_texts= list(df_org.Comment[:SIZE//2])\n",
    "\n",
    "val_texts=   list(df_org.Comment[SIZE//2:(3*SIZE)//4 ])\n",
    "\n",
    "test_texts=  list(df_org.Comment[(3*SIZE)//4:])\n",
    "\n",
    "train_labels= list(df_org.labels[:SIZE//2])\n",
    "\n",
    "val_labels=   list(df_org.labels[SIZE//2:(3*SIZE)//4])\n",
    "\n",
    "test_labels=  list(df_org.labels[(3*SIZE)//4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14370"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1625398221030,
     "user": {
      "displayName": "Savas Yıldırım",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64",
      "userId": "10717726124681851716"
     },
     "user_tz": -180
    },
    "id": "vwe5Bt8CfhdU",
    "outputId": "619c0354-0462-485e-804c-b5df86b7d713"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14370, 7185, 7185)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_texts), len(val_texts), len(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4406,
     "status": "ok",
     "timestamp": 1625398225432,
     "user": {
      "displayName": "Savas Yıldırım",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64",
      "userId": "10717726124681851716"
     },
     "user_tz": -180
    },
    "id": "snOgiQe2mbpx"
   },
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
    "val_encodings  = tokenizer(val_texts, truncation=True, padding=True)\n",
    "test_encodings = tokenizer(test_texts, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader(Dataset):\n",
    "    \"\"\"\n",
    "    Custom Dataset class for handling tokenized text data and corresponding labels.\n",
    "    Inherits from torch.utils.data.Dataset.\n",
    "    \"\"\"\n",
    "    def __init__(self, encodings, labels):\n",
    "        \"\"\"\n",
    "        Initializes the DataLoader class with encodings and labels.\n",
    "\n",
    "        Args:\n",
    "            encodings (dict): A dictionary containing tokenized input text data\n",
    "                              (e.g., 'input_ids', 'token_type_ids', 'attention_mask').\n",
    "            labels (list): A list of integer labels for the input text data.\n",
    "        \"\"\"\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns a dictionary containing tokenized data and the corresponding label for a given index.\n",
    "\n",
    "        Args:\n",
    "            idx (int): The index of the data item to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            item (dict): A dictionary containing the tokenized data and the corresponding label.\n",
    "        \"\"\"\n",
    "        # Retrieve tokenized data for the given index\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        # Add the label for the given index to the item dictionary\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the number of data items in the dataset.\n",
    "\n",
    "        Returns:\n",
    "            (int): The number of data items in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.labels)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From above DataLoader() The line `item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}`\n",
    "\n",
    "Here I use a dictionary comprehension that constructs a new dictionary called `item`. This line converts the encoding values associated with the input text at the given index idx into PyTorch tensors.\n",
    "\n",
    "self.encodings is a dictionary containing tokenized input text with keys like 'input_ids', 'token_type_ids', and 'attention_mask'. These keys represent different aspects of the encoded text that are needed for processing by the BERT model. The values associated with these keys are lists or arrays of integers.\n",
    "\n",
    ".items() is a method that returns a view object displaying a list of a dictionary's key-value pairs as tuples.\n",
    "\n",
    "The dictionary comprehension iterates through the key-value pairs of self.encodings with the variables key and val. For each key-value pair, it creates a new key-value pair in the item dictionary, where the key remains the same, and the value is a PyTorch tensor created from the elements at index idx of the original value.\n",
    "\n",
    "In essence, this line of code is converting the relevant parts of the input encodings (e.g., input IDs, attention masks) at the given index idx into PyTorch tensors and storing them in a new dictionary called item. This format is necessary for input to the BERT model during training or evaluation.\n",
    "\n",
    "Here's an example of the output format for self.encodings:\n",
    "\n",
    "\n",
    "```\n",
    "{\n",
    "    'input_ids': [\n",
    "        [101, 2023, 2003, 1037, 2742, 102],\n",
    "        [101, 1045, 2066, 5009, 2102, 102],\n",
    "        [101, 2129, 2024, 2017, 1029, 102]\n",
    "    ],\n",
    "    'token_type_ids': [\n",
    "        [0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0]\n",
    "    ],\n",
    "    'attention_mask': [\n",
    "        [1, 1, 1, 1, 1, 1],\n",
    "        [1, 1, 1, 1, 1, 1],\n",
    "        [1, 1, 1, 1, 1, 1]\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "In this example, there are three input sentences, each encoded into three different features: input_ids, token_type_ids, and attention_mask.\n",
    "\n",
    "* input_ids: Lists of token IDs that represent the input text. The integers correspond to the tokens in the tokenizer's vocabulary.\n",
    "\n",
    "* token_type_ids: Lists of token type IDs that indicate the type of each token. In this case, they are all 0 since there is only one sentence per input. In tasks that require sentence pairs, you would see different token type IDs for different sentences.\n",
    "\n",
    "* attention_mask: Lists of binary values that indicate whether a given token should be attended to (1) or not (0). In this example, all tokens are attended to, so all the values are 1. Padding tokens would have a value of 0 in the attention_mask.\n",
    "\n",
    "Note that this example assumes that the maximum sequence length is 6 tokens, and there's no need for padding or truncation. In practice, you would have longer sequences, and padding would be necessary to make all the input sequences have the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 412,
     "status": "ok",
     "timestamp": 1625398229008,
     "user": {
      "displayName": "Savas Yıldırım",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64",
      "userId": "10717726124681851716"
     },
     "user_tz": -180
    },
    "id": "Vx3u-9ljtmM_"
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_encodings, train_labels)\n",
    "\n",
    "val_dataloader = DataLoader(val_encodings, val_labels)\n",
    "\n",
    "test_dataset = DataLoader(test_encodings, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    \"\"\"\n",
    "    Computes accuracy, F1, precision, and recall for a given set of predictions.\n",
    "    \n",
    "    Args:\n",
    "        pred (obj): An object containing label_ids and predictions attributes.\n",
    "            - label_ids (array-like): A 1D array of true class labels.\n",
    "            - predictions (array-like): A 2D array where each row represents\n",
    "              an observation, and each column represents the probability of \n",
    "              that observation belonging to a certain class.\n",
    "              \n",
    "    Returns:\n",
    "        dict: A dictionary containing the following metrics:\n",
    "            - Accuracy (float): The proportion of correctly classified instances.\n",
    "            - F1 (float): The macro F1 score, which is the harmonic mean of precision\n",
    "              and recall. Macro averaging calculates the metric independently for\n",
    "              each class and then takes the average.\n",
    "            - Precision (float): The macro precision, which is the number of true\n",
    "              positives divided by the sum of true positives and false positives.\n",
    "            - Recall (float): The macro recall, which is the number of true positives\n",
    "              divided by the sum of true positives and false negatives.\n",
    "    \"\"\"\n",
    "    # Extract true labels from the input object\n",
    "    labels = pred.label_ids\n",
    "    \n",
    "    # Obtain predicted class labels by finding the column index with the maximum probability\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    \n",
    "    # Compute macro precision, recall, and F1 score using sklearn's precision_recall_fscore_support function\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n",
    "    \n",
    "    # Calculate the accuracy score using sklearn's accuracy_score function\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    \n",
    "    # Return the computed metrics as a dictionary\n",
    "    return {\n",
    "        'Accuracy': acc,\n",
    "        'F1': f1,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./TTC4900Model', \n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "\n",
    "    # Reduce number of epochs (tune as needed)\n",
    "    num_train_epochs=1,              \n",
    "\n",
    "    # Adjust batch size to what your GPU can handle (bigger = faster)\n",
    "    per_device_train_batch_size=32,  \n",
    "    per_device_eval_batch_size=64,  \n",
    "\n",
    "    # Warmup and weight decay\n",
    "    warmup_steps=0,                 # Reduce warmup if not needed\n",
    "    weight_decay=0.01,              # Lowered slightly for speed\n",
    "\n",
    "    # Logging and evaluation frequency (less frequent = faster)\n",
    "    logging_strategy='steps',\n",
    "    logging_dir='./multi-class-logs',            \n",
    "    logging_steps=50,               # Log less often\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=100,                 # Evaluate less often\n",
    "    save_strategy=\"steps\", \n",
    "    save_steps=200,                 # Save checkpoints less often\n",
    "\n",
    "    # Enable mixed precision training for speed\n",
    "    fp16=True,                      \n",
    "\n",
    "    # Stops early if no improvement\n",
    "    load_best_model_at_end=True,             \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    # the pre-trained model that will be fine-tuned \n",
    "    model=model,\n",
    "     # training arguments that we defined above                        \n",
    "    args=training_args,                 \n",
    "    train_dataset=train_dataloader,         \n",
    "    eval_dataset=val_dataloader,            \n",
    "    compute_metrics= compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='2697' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   6/2697 01:12 < 13:30:37, 0.06 it/s, Epoch 0.01/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='225' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 39/225 06:20 < 31:02, 0.10 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-dXcl4LWBsJy"
   },
   "source": [
    "## Training with Trainer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "executionInfo": {
     "elapsed": 85330,
     "status": "ok",
     "timestamp": 1625399043817,
     "user": {
      "displayName": "Savas Yıldırım",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64",
      "userId": "10717726124681851716"
     },
     "user_tz": -180
    },
    "id": "FN2i7kRIj-UQ",
    "outputId": "71974f34-e461-4999-9ab8-558783167509"
   },
   "outputs": [],
   "source": [
    "q=[trainer.evaluate(eval_dataset=df_org) for df_org in [train_dataloader, val_dataloader, test_dataset]]\n",
    "\n",
    "pd.DataFrame(q, index=[\"train\",\"val\",\"test\"]).iloc[:,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 392,
     "status": "ok",
     "timestamp": 1625399048192,
     "user": {
      "displayName": "Savas Yıldırım",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64",
      "userId": "10717726124681851716"
     },
     "user_tz": -180
    },
    "id": "I0guPT0jYJth"
   },
   "outputs": [],
   "source": [
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    \"\"\"\n",
    "    Predicts the class label for a given input text\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text for which the class label needs to be predicted.\n",
    "\n",
    "    Returns:\n",
    "        probs (torch.Tensor): Class probabilities for the input text.\n",
    "        pred_label_idx (torch.Tensor): The index of the predicted class label.\n",
    "        pred_label (str): The predicted class label.\n",
    "    \"\"\"\n",
    "    # Tokenize the input text and move tensors to the GPU if available\n",
    "    inputs = tokenizer(text, padding=True, truncation=True, max_length=512, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    # Get model output (logits)\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    probs = outputs[0].softmax(1)\n",
    "    \"\"\" Explanation outputs: The BERT model returns a tuple containing the output logits (and possibly other elements depending on the model configuration). In this case, the output logits are the first element in the tuple, which is why we access it using outputs[0].\n",
    "\n",
    "    outputs[0]: This is a tensor containing the raw output logits for each class. The shape of the tensor is (batch_size, num_classes) where batch_size is the number of input samples (in this case, 1, as we are predicting for a single input text) and num_classes is the number of target classes.\n",
    "\n",
    "    softmax(1): The softmax function is applied along dimension 1 (the class dimension) to convert the raw logits into class probabilities. Softmax normalizes the logits so that they sum to 1, making them interpretable as probabilities. \"\"\"\n",
    "\n",
    "    # Get the index of the class with the highest probability\n",
    "    # argmax() finds the index of the maximum value in the tensor along a specified dimension.\n",
    "    # By default, if no dimension is specified, it returns the index of the maximum value in the flattened tensor.\n",
    "    pred_label_idx = probs.argmax()\n",
    "\n",
    "    # Now map the predicted class index to the actual class label \n",
    "    # Since pred_label_idx is a tensor containing a single value (the predicted class index), \n",
    "    # the .item() method is used to extract the value as a scalar\n",
    "    pred_label = model.config.id2label[pred_label_idx.item()]\n",
    "\n",
    "    return probs, pred_label_idx, pred_label\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "WWoJjzP6aYlc"
   },
   "source": [
    "## Save model for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2155,
     "status": "ok",
     "timestamp": 1625399060094,
     "user": {
      "displayName": "Savas Yıldırım",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64",
      "userId": "10717726124681851716"
     },
     "user_tz": -180
    },
    "id": "aF7GVSKSYBPw",
    "outputId": "a0bcea98-9f37-460f-bf56-fa7604edd970"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mturkish-text-classification-model\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241m.\u001b[39msave_model(model_path)\n\u001b[0;32m      3\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39msave_pretrained(model_path)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "model_path = \"turkish-text-classification-model\"\n",
    "trainer.save_model(model_path)\n",
    "tokenizer.save_pretrained(model_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-Load saved model for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2937,
     "status": "ok",
     "timestamp": 1625399066951,
     "user": {
      "displayName": "Savas Yıldırım",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64",
      "userId": "10717726124681851716"
     },
     "user_tz": -180
    },
    "id": "qEYQdBL8Tdkm",
    "outputId": "0e6b93fa-32ab-481d-e676-94dd051acec6"
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "turkish-text-classification-model is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32md:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\huggingface_hub\\utils\\_http.py:409\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 409\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32md:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\requests\\models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/turkish-text-classification-model/resolve/main/config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "File \u001b[1;32md:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\transformers\\utils\\hub.py:342\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[1;32m--> 342\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    343\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    345\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32md:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\huggingface_hub\\file_download.py:862\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[1;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[0;32m    864\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[0;32m    866\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[0;32m    871\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    873\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[0;32m    877\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\huggingface_hub\\file_download.py:969\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[1;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;66;03m# Otherwise, raise appropriate error\u001b[39;00m\n\u001b[1;32m--> 969\u001b[0m     \u001b[43m_raise_on_head_call_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead_call_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[38;5;66;03m# From now on, etag, commit_hash, url and size are not None.\u001b[39;00m\n",
      "File \u001b[1;32md:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\huggingface_hub\\file_download.py:1486\u001b[0m, in \u001b[0;36m_raise_on_head_call_error\u001b[1;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[0;32m   1481\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, (RepositoryNotFoundError, GatedRepoError)) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   1482\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(head_call_error, HfHubHTTPError) \u001b[38;5;129;01mand\u001b[39;00m head_call_error\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m401\u001b[39m\n\u001b[0;32m   1483\u001b[0m ):\n\u001b[0;32m   1484\u001b[0m     \u001b[38;5;66;03m# Repo not found or gated => let's raise the actual error\u001b[39;00m\n\u001b[0;32m   1485\u001b[0m     \u001b[38;5;66;03m# Unauthorized => likely a token issue => let's raise the actual error\u001b[39;00m\n\u001b[1;32m-> 1486\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m head_call_error\n\u001b[0;32m   1487\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1488\u001b[0m     \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n",
      "File \u001b[1;32md:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\huggingface_hub\\file_download.py:1376\u001b[0m, in \u001b[0;36m_get_metadata_or_catch_error\u001b[1;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[0;32m   1375\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1376\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1377\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\n\u001b[0;32m   1378\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1379\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n",
      "File \u001b[1;32md:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\huggingface_hub\\file_download.py:1296\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[1;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[0;32m   1295\u001b[0m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[1;32m-> 1296\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHEAD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1298\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1300\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1303\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1304\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1305\u001b[0m hf_raise_for_status(r)\n",
      "File \u001b[1;32md:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\huggingface_hub\\file_download.py:280\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[1;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[1;32m--> 280\u001b[0m     response \u001b[38;5;241m=\u001b[39m _request_wrapper(\n\u001b[0;32m    281\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m    282\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m    283\u001b[0m         follow_relative_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    284\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    285\u001b[0m     )\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[0;32m    288\u001b[0m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "File \u001b[1;32md:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\huggingface_hub\\file_download.py:304\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[1;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[0;32m    303\u001b[0m response \u001b[38;5;241m=\u001b[39m get_session()\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m--> 304\u001b[0m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32md:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\huggingface_hub\\utils\\_http.py:458\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    450\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    451\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    452\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    456\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m make sure you are authenticated.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    457\u001b[0m     )\n\u001b[1;32m--> 458\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _format(RepositoryNotFoundError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m400\u001b[39m:\n",
      "\u001b[1;31mRepositoryNotFoundError\u001b[0m: 401 Client Error. (Request ID: Root=1-67e02db5-58615ac15cab5ffd2d9fba8c;4c09f8be-6cad-40a5-97b0-79f2766c306c)\n\nRepository Not Found for url: https://huggingface.co/turkish-text-classification-model/resolve/main/config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.\nInvalid username or password.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mturkish-text-classification-model\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mBertForSequenceClassification\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m tokenizer\u001b[38;5;241m=\u001b[39m BertTokenizerFast\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_path)\n\u001b[0;32m      6\u001b[0m nlp\u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentiment-analysis\u001b[39m\u001b[38;5;124m\"\u001b[39m, model\u001b[38;5;241m=\u001b[39mmodel, tokenizer\u001b[38;5;241m=\u001b[39mtokenizer)\n",
      "File \u001b[1;32md:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\transformers\\modeling_utils.py:262\u001b[0m, in \u001b[0;36mrestore_default_torch_dtype.<locals>._wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    260\u001b[0m old_dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mget_default_dtype()\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 262\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    264\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_default_dtype(old_dtype)\n",
      "File \u001b[1;32md:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\transformers\\modeling_utils.py:3540\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   3537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m commit_hash \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3538\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, PretrainedConfig):\n\u001b[0;32m   3539\u001b[0m         \u001b[38;5;66;03m# We make a call to the config file first (which may be absent) to get the commit hash as soon as possible\u001b[39;00m\n\u001b[1;32m-> 3540\u001b[0m         resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3541\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3542\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3543\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3544\u001b[0m \u001b[43m            \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3545\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3546\u001b[0m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3547\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3548\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3549\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3550\u001b[0m \u001b[43m            \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3551\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_gated_repo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   3552\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_missing_entries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   3553\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_connection_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   3554\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3555\u001b[0m         commit_hash \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[0;32m   3556\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Arun Nitc\\New folder\\envs\\py310\\lib\\site-packages\\transformers\\utils\\hub.py:365\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    360\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    361\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to access a gated repo.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMake sure to have access to it at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    364\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 365\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    366\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a local folder and is not a valid model identifier \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    367\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlisted on \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIf this is a private repository, make sure to pass a token \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    368\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhaving permission to this repo either by logging in with `huggingface-cli login` or by passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    369\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`token=<your_token>`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    370\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RevisionNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    372\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    373\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a valid git identifier (branch name, tag name or commit id) that exists \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    374\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor this model name. Check the model page at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    375\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for available revisions.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    376\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mOSError\u001b[0m: turkish-text-classification-model is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`"
     ]
    }
   ],
   "source": [
    "model_path = \"turkish-text-classification-model\"\n",
    "\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer= BertTokenizerFast.from_pretrained(model_path)\n",
    "nlp= pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 533,
     "status": "ok",
     "timestamp": 1625399077112,
     "user": {
      "displayName": "Savas Yıldırım",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64",
      "userId": "10717726124681851716"
     },
     "user_tz": -180
    },
    "id": "zyiJkIvzcdgC",
    "outputId": "ddd71497-8990-4cde-95b9-99882f33bb17"
   },
   "outputs": [],
   "source": [
    "nlp(\"Bugün hava çok güzel, dışarıda yürümek istiyorum.\")\n",
    "# Today the weather is very nice, I want to go for a walk outside\n",
    "\n",
    "# Gives below output\n",
    "#[{'label': 'saglik', 'score': 0.8295329213142395}]\n",
    "# \"Saglik\" is a Turkish word that means \"health\" in English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 515,
     "status": "ok",
     "timestamp": 1625399079590,
     "user": {
      "displayName": "Savas Yıldırım",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64",
      "userId": "10717726124681851716"
     },
     "user_tz": -180
    },
    "id": "RPLqmWPMGc53",
    "outputId": "4070ccb8-9f2d-491e-b96e-0e8202777c07"
   },
   "outputs": [],
   "source": [
    "nlp(\"Derin Öğrenme ve Yapay Zeka dünyayı değiştirecek.\")\n",
    "# Deep Learning and AI is going to change the world\n",
    "\n",
    "# gives below output\n",
    "#[{'label': 'teknoloji', 'score': 0.9932782053947449}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 632,
     "status": "ok",
     "timestamp": 1625399082230,
     "user": {
      "displayName": "Savas Yıldırım",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhdhYZMfq-hvK2xI7HqkzvJuCbfgFrIs4wypQEm5w=s64",
      "userId": "10717726124681851716"
     },
     "user_tz": -180
    },
    "id": "5hc65L_mQcVf",
    "outputId": "43a2bda2-c915-47b5-f29c-8319bf76deeb"
   },
   "outputs": [],
   "source": [
    "nlp(\"Son zamanlarda ekonomideki oynaklık nedeniyle, borsa endeksi oldukça düşük seviyelerde seyrediyor.\")\n",
    "# Due to recent volatility in the economy, the stock market index has been at quite low levels\n",
    "\n",
    "#gives below output\n",
    "#[{'label': 'ekonomi', 'score': 0.9850727915763855}]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyO2hBd/tE18yqAA78qNBNVu",
   "collapsed_sections": [],
   "name": "CH05c_Multi-class_Classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0479af3dea114a4b86c98cd104325344": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1886bd7f86534fcea494bef48439e7db": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "21fbbe9bd6d94f308668ac1e4c2a51d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d9bad87a40624bbe9a7b8e5021b6b878",
       "IPY_MODEL_6f869fe141f847a881532c74c5d8b269"
      ],
      "layout": "IPY_MODEL_f391632fced34067a6bc7f76034d8d38"
     }
    },
    "35a5b5e6ff374b6a80e8677d695a5409": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "395f10a793684087b6e3747154e17f8d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_94930151f87e495b974a7f40de2b1db4",
      "max": 59,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b3652deb88d94a3e91bc0fa58b9dce54",
      "value": 59
     }
    },
    "43a1a07853414f1fbd41c1d7a7e2a7fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4557e0d687a44a8ab109109094f3ebd6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0479af3dea114a4b86c98cd104325344",
      "placeholder": "​",
      "style": "IPY_MODEL_d391715c96a84d078976a10fab20265a",
      "value": " 385/385 [00:34&lt;00:00, 11.2B/s]"
     }
    },
    "4622af58d24f4eea8f67f49364118ccd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "4e66a8a8057e4232a3881aef3ac3afa9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5db915425bac4d9caba753797e9faf29": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "6613484a4d0c477fb4ec5a3d4da81a73": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "66f31b78d9974a51bd28e01d073b72a7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6f869fe141f847a881532c74c5d8b269": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_66f31b78d9974a51bd28e01d073b72a7",
      "placeholder": "​",
      "style": "IPY_MODEL_43a1a07853414f1fbd41c1d7a7e2a7fd",
      "value": " 263k/263k [00:01&lt;00:00, 133kB/s]"
     }
    },
    "85c4358f5a6e411fbff53e3dfe3eb88d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b42f5e933f494ea69f3dbaac391b5e23",
      "max": 445018749,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4622af58d24f4eea8f67f49364118ccd",
      "value": 445018749
     }
    },
    "8ed902a5a04e4bdaac8f961afe52b622": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_395f10a793684087b6e3747154e17f8d",
       "IPY_MODEL_c905e0961cf84af2bec6a29ddc0d4237"
      ],
      "layout": "IPY_MODEL_95a51d9d15734391a3895ac76b7a3676"
     }
    },
    "94930151f87e495b974a7f40de2b1db4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "95a51d9d15734391a3895ac76b7a3676": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a098193923044bfc89afdfa4faf8cc25": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b3652deb88d94a3e91bc0fa58b9dce54": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "b42f5e933f494ea69f3dbaac391b5e23": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b9f606782e924fdd9a22ee6039ef76f2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bed0bf19829f4957985091c7f308190c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c905e0961cf84af2bec6a29ddc0d4237": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a098193923044bfc89afdfa4faf8cc25",
      "placeholder": "​",
      "style": "IPY_MODEL_4e66a8a8057e4232a3881aef3ac3afa9",
      "value": " 59.0/59.0 [00:00&lt;00:00, 730B/s]"
     }
    },
    "ce256db990954d9f9782eae9a248b40b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6613484a4d0c477fb4ec5a3d4da81a73",
      "max": 385,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5db915425bac4d9caba753797e9faf29",
      "value": 385
     }
    },
    "cfe8a0c3575a49b6b298262ed7acf76d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dd7628d863794892b9b1fdd7c5e5df42",
      "placeholder": "​",
      "style": "IPY_MODEL_f92aca32755f45c3ba2b8cab79d44eed",
      "value": " 445M/445M [00:09&lt;00:00, 49.2MB/s]"
     }
    },
    "d391715c96a84d078976a10fab20265a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d9bad87a40624bbe9a7b8e5021b6b878": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bed0bf19829f4957985091c7f308190c",
      "max": 262620,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_35a5b5e6ff374b6a80e8677d695a5409",
      "value": 262620
     }
    },
    "dd7628d863794892b9b1fdd7c5e5df42": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eda88132d04243bcb499af9e82a789ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ce256db990954d9f9782eae9a248b40b",
       "IPY_MODEL_4557e0d687a44a8ab109109094f3ebd6"
      ],
      "layout": "IPY_MODEL_b9f606782e924fdd9a22ee6039ef76f2"
     }
    },
    "f391632fced34067a6bc7f76034d8d38": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f8532b3abd7e4243a8fb0ade8e0540e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_85c4358f5a6e411fbff53e3dfe3eb88d",
       "IPY_MODEL_cfe8a0c3575a49b6b298262ed7acf76d"
      ],
      "layout": "IPY_MODEL_1886bd7f86534fcea494bef48439e7db"
     }
    },
    "f92aca32755f45c3ba2b8cab79d44eed": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
